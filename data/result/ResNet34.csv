accuracy,f1,recall,precision
train,76.7491108516819,0.6361309523809523,0.659375,0.6291666666666667
val,76.32462888720339,0.6923076923076923,0.6923076923076923,0.6923076923076923
train,79.15184752803192,0.7228442728442728,0.7207207207207207,0.742117117117117
val,79.2501896196771,0.5714285714285714,0.5714285714285714,0.5714285714285714
train,80.87855998696821,0.8025974025974025,0.8073593073593074,0.8116883116883117
val,80.81048867699643,0.5,0.5,0.5
train,81.4785654168816,0.8141552511415525,0.815068493150685,0.8287671232876712
val,81.27641131216816,0.5416666666666666,0.5625,0.53125
train,82.15730459099177,0.7723577235772358,0.7764227642276423,0.7764227642276423
val,81.75316935746018,0.625,0.625,0.625
train,82.61884722938669,0.8190476190476191,0.8290043290043291,0.8203463203463203
val,82.44663560515765,0.7333333333333333,0.7333333333333333,0.7333333333333333
train,83.10753943474602,0.7746666666666667,0.7822222222222222,0.78
val,82.55498970636039,0.6666666666666666,0.6538461538461539,0.6923076923076923
train,83.55822224635517,0.7816798941798941,0.7835648148148149,0.7974537037037037
val,83.23762054393758,0.8571428571428571,0.8571428571428571,0.8571428571428571
train,83.2867265767111,0.7133848133848134,0.7353603603603603,0.7139639639639639
val,82.78253331888612,0.5294117647058824,0.5294117647058824,0.5294117647058824
train,83.59080172671246,0.756578947368421,0.7686403508771931,0.7631578947368421
val,82.83671036948749,1.0,1.0,1.0
final train,83.82157304590991,0.6940308517773306,0.7075117370892019,0.7145539906103286
final val,82.57666052660093,0.7619047619047619,0.75,0.7857142857142857
