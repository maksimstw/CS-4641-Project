accuracy,f1,recall,precision
train,76.52376944587735,0.6934942991281019,0.7136150234741784,0.7098591549295774
val,75.64199804962618,0.3684210526315789,0.3684210526315789,0.3684210526315789
train,79.81429696196346,0.7008547008547008,0.7264957264957265,0.6965811965811965
val,78.1666486076498,0.8461538461538461,0.8461538461538461,0.8461538461538461
train,81.94282301197295,0.8268398268398268,0.8441558441558441,0.8246753246753247
val,80.63712211507206,0.7142857142857143,0.7142857142857143,0.7142857142857143
train,82.5998425325116,0.7236164736164735,0.7308558558558559,0.7443693693693693
val,81.15722180084516,0.7142857142857143,0.7142857142857143,0.7142857142857143
train,82.55911818206499,0.7052631578947368,0.7236842105263158,0.7225877192982456
val,81.88319427890346,0.6538461538461539,0.6923076923076923,0.641025641025641
train,82.80074932804821,0.7324894514767932,0.75,0.7383966244725738
val,81.53646115505472,0.8571428571428571,0.8571428571428571,0.8571428571428571
train,83.88944696332094,0.7627705627705628,0.761904761904762,0.7705627705627704
val,82.59833134684148,0.625,0.625,0.625
train,83.63695599055195,0.6954166666666667,0.7083333333333334,0.7020833333333333
val,82.3491169140752,0.5,0.5,0.5
train,84.11750332582196,0.7679653679653681,0.7878787878787878,0.7575757575757576
val,82.57666052660093,0.625,0.625,0.625
train,83.98175549099992,0.6789029535864978,0.6951476793248945,0.6919831223628692
val,82.05656084082783,0.8571428571428571,0.8571428571428571,0.8571428571428571
final train,83.76184399858822,0.7730593607305937,0.8036529680365296,0.7694063926940639
final val,82.19742117239137,1.0,1.0,1.0
